{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3904d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # 운영 체제와 상호작용하기 위한 모듈\n",
    "import shutil  # 파일 및 디렉토리 작업을 위한 모듈\n",
    "import random  # 랜덤 작업을 위한 모듈\n",
    "import scipy  # 과학 및 기술 계산을 위한 모듈\n",
    "import numpy as np  # 수치 연산을 위한 Python 라이브러리\n",
    "import matplotlib.pyplot as plt  # 데이터 시각화를 위한 라이브러리\n",
    "import tensorflow as tf  # 텐서플로우 라이브러리\n",
    "import keras  # 케라스 라이브러리\n",
    "from keras.preprocessing.image import ImageDataGenerator  # 이미지 데이터 생성기 유틸리티\n",
    "from keras.models import Model  # Keras의 함수형 API 모델\n",
    "from keras.layers import (Conv2D, DepthwiseConv2D, LayerNormalization, Dense, GlobalAveragePooling2D, \n",
    "                          Input, Layer, BatchNormalization, Activation, Softmax)  # 신경망의 레이어 구성 요소\n",
    "from keras.optimizers import Adam  # Adam 최적화 알고리즘\n",
    "from tensorflow_addons.optimizers import AdamW  # AdamW 최적화 알고리즘\n",
    "from keras.losses import CategoricalCrossentropy  # 손실 함수\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau  # 학습 중 콜백 함수\n",
    "\n",
    "# 데이터 생성기 설정 함수\n",
    "def generators(train_dir, val_dir, size=64, image_size=64):\n",
    "    \"\"\"학습 및 검증 데이터를 생성하는 함수\"\"\"\n",
    "    # 학습 데이터 생성기 설정\n",
    "    train_datagen = ImageDataGenerator(rescale=1/255,  # 이미지의 픽셀 값을 0-1 범위로 정규화\n",
    "                                       rotation_range=180,  # 최대 180도 회전\n",
    "                                       width_shift_range=0.2,  # 가로 방향 이동\n",
    "                                       height_shift_range=0.2,  # 세로 방향 이동\n",
    "                                       shear_range=0.2,  # 시어 변환\n",
    "                                       zoom_range=0.2,  # 줌 인/줌 아웃\n",
    "                                       horizontal_flip=True,  # 가로 방향 뒤집기\n",
    "                                       vertical_flip=True,  # 세로 방향 뒤집기\n",
    "                                       fill_mode='nearest')  # 변환 중 생기는 빈 공간을 주변의 유사한 픽셀 값으로 채우기\n",
    "\n",
    "    # 검증 데이터 생성기 설정\n",
    "    val_datagen = ImageDataGenerator(rescale=1/255)  # 이미지의 픽셀 값을 0-1 범위로 정규화\n",
    "\n",
    "    # 학습 데이터 생성\n",
    "    train_generator = train_datagen.flow_from_directory(train_dir,  # 학습 데이터가 위치한 디렉토리\n",
    "                                                        target_size=(image_size, image_size),  # 입력 이미지 크기\n",
    "                                                        batch_size=size,  # 배치 크기\n",
    "                                                        class_mode='categorical',  # 다중 클래스 분류\n",
    "                                                        shuffle=True)  # 데이터를 섞어서 배치 생성\n",
    "\n",
    "    # 검증 데이터 생성\n",
    "    val_generator = val_datagen.flow_from_directory(val_dir,  # 검증 데이터가 위치한 디렉토리\n",
    "                                                    target_size=(image_size, image_size),  # 입력 이미지 크기\n",
    "                                                    batch_size=size,  # 배치 크기\n",
    "                                                    class_mode='categorical')  # 다중 클래스 분류\n",
    "\n",
    "    return train_generator, val_generator  # 학습 및 검증 데이터 생성기 반환\n",
    "\n",
    "# 학습 및 검증 데이터 디렉토리 설정\n",
    "train_dir = 'your_path'\n",
    "val_dir = 'your_path'\n",
    "\n",
    "# 데이터 생성기 생성\n",
    "train_generator, val_generator = generators(train_dir, val_dir)\n",
    "\n",
    "# Local Perception Unit (LPU) 클래스 정의\n",
    "class LocalPerceptionUnit(Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(LocalPerceptionUnit, self).__init__()\n",
    "        self.dw_conv = DepthwiseConv2D(kernel_size=3, padding='same')\n",
    "        self.filters = filters\n",
    "\n",
    "    def call(self, x):\n",
    "        return x + self.dw_conv(x)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"filters\": self.filters})\n",
    "        return config\n",
    "\n",
    "# Lightweight Multi-Head Self-Attention (MHSA) 클래스 정의\n",
    "class LightweightMHSA(Layer):\n",
    "    def __init__(self, dim, num_heads=8):\n",
    "        super(LightweightMHSA, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.dim = dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.qkv = Dense(self.dim * 3)\n",
    "        self.proj = Dense(self.dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        B, H, W, C = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2], self.dim\n",
    "        N = H * W  # Flattened spatial dimensions\n",
    "        qkv = self.qkv(x)\n",
    "        qkv = tf.reshape(qkv, (B, N, 3, self.num_heads, C // self.num_heads))\n",
    "        qkv = tf.transpose(qkv, perm=[2, 0, 3, 1, 4])\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        attn = tf.nn.softmax(tf.matmul(q, k, transpose_b=True) / (C // self.num_heads) ** 0.5, axis=-1)\n",
    "        attn = tf.matmul(attn, v)\n",
    "\n",
    "        attn = tf.transpose(attn, perm=[0, 2, 1, 3])\n",
    "        attn = tf.reshape(attn, (B, H, W, C))\n",
    "\n",
    "        return self.proj(attn)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"dim\": self.dim, \"num_heads\": self.num_heads})\n",
    "        return config\n",
    "\n",
    "# Inverted Residual Feed-Forward Network (FFN) 클래스 정의\n",
    "class InvertedResidualFFN(Layer):\n",
    "    def __init__(self, dim, expansion_ratio=4):\n",
    "        super(InvertedResidualFFN, self).__init__()\n",
    "        self.hidden_dim = int(dim * expansion_ratio)\n",
    "        self.expand = Dense(self.hidden_dim)\n",
    "        self.depthwise = DepthwiseConv2D(kernel_size=3, padding='same')\n",
    "        self.project = Dense(dim)\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.gelu = Activation('gelu')\n",
    "\n",
    "    def call(self, x):\n",
    "        residual = x\n",
    "        x = self.expand(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.depthwise(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.project(x)\n",
    "        return residual + x\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"dim\": self.hidden_dim // 4, \"expansion_ratio\": 4})\n",
    "        return config\n",
    "\n",
    "# CMTBlock (Convolutional Multi-head Self-Attention Block) 클래스 정의\n",
    "class CMTBlock(Layer):\n",
    "    def __init__(self, dim, num_heads=8, mlp_ratio=4.):\n",
    "        super(CMTBlock, self).__init__()\n",
    "        self.lpu = LocalPerceptionUnit(dim)\n",
    "        self.lmhsa = LightweightMHSA(dim, num_heads)\n",
    "        self.irffn = InvertedResidualFFN(dim, mlp_ratio)\n",
    "        self.norm1 = LayerNormalization()\n",
    "        self.norm2 = LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.lpu(x)\n",
    "        x = x + self.lmhsa(self.norm1(x))\n",
    "        x = x + self.irffn(self.norm2(x))\n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"dim\": self.lpu.filters,\n",
    "            \"num_heads\": self.lmhsa.num_heads,\n",
    "            \"mlp_ratio\": self.irffn.hidden_dim // self.lpu.filters\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# CMT-S 모델 정의 함수\n",
    "def cmt_s(input_shape=(224, 224, 3), num_classes=1000):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Stem\n",
    "    x = Conv2D(32, kernel_size=3, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('gelu')(x)\n",
    "    x = Conv2D(32, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('gelu')(x)\n",
    "    x = Conv2D(32, kernel_size=3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('gelu')(x)\n",
    "    \n",
    "    # Stage 1\n",
    "    x = Conv2D(64, kernel_size=2, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('gelu')(x)\n",
    "    for _ in range(3):\n",
    "        x = CMTBlock(64)(x)\n",
    "        \n",
    "    # Stage 2\n",
    "    x = Conv2D(128, kernel_size=2, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('gelu')(x)\n",
    "    for _ in range(3):\n",
    "        x = CMTBlock(128)(x)\n",
    "    \n",
    "    # Stage 3\n",
    "    x = Conv2D(256, kernel_size=2, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('gelu')(x)\n",
    "    for _ in range(16):\n",
    "        x = CMTBlock(256)(x)\n",
    "    \n",
    "    # Stage 4\n",
    "    x = Conv2D(512, kernel_size=2, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('gelu')(x)\n",
    "    for _ in range(3):\n",
    "        x = CMTBlock(512)(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = Dense(1280)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('gelu')(x)\n",
    "    \n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# 모델 생성 및 컴파일\n",
    "model = cmt_s(input_shape=(64, 64, 3), num_classes=100)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4, decay=5e-9), loss=CategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model.summary()\n",
    "\n",
    "# 모델 체크포인트 및 조기 종료 콜백 설정\n",
    "model_path = 'your_path'\n",
    "CP = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "ES = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(train_generator, epochs=100, validation_data=val_generator, batch_size=16, callbacks=[CP, ES])\n",
    "\n",
    "# 학습 결과 시각화\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('CMT_S Model')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'accuracy', 'val_loss', 'val_accuracy'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# 최적의 검증 정확도와 손실 출력\n",
    "print('Best Val Acc:', max(history.history['val_accuracy']))\n",
    "print('Best Val Loss:', min(history.history['val_loss']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
