{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100bbf0d-ef62-4da8-b48e-43f84743f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # 운영 체제와 상호작용하기 위한 모듈\n",
    "import numpy as np  # 수치 연산을 위한 Python 라이브러리\n",
    "import tensorflow as tf  # 딥러닝 라이브러리 TensorFlow\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # 이미지 불러오기 및 배열로 변환하기 위한 Keras 유틸리티\n",
    "import matplotlib.pyplot as plt  # 데이터 시각화를 위한 라이브러리\n",
    "from tensorflow.keras import mixed_precision  # 혼합 정밀도 계산을 위한 모듈\n",
    "from tqdm import tqdm  # 진행 상황 표시를 위한 모듈\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint  # 학습 중간에 모델을 저장하기 위한 콜백 함수\n",
    "\n",
    "# GPU 설정: 5, 6, 7번 GPU만 사용하도록 설정\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"your_GPU\"\n",
    "\n",
    "def setup_gpus():\n",
    "    \"\"\"GPU 메모리 증가를 동적으로 설정\"\"\"\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "\n",
    "setup_gpus()\n",
    "\n",
    "# 혼합 정밀도 설정\n",
    "\"\"\"\n",
    "혼합 정밀도(Mixed Precision)는 딥러닝 모델 학습에서 16비트 부동 소수점(float16)과 32비트 부동 소수점(float32) 숫자 표현을 결합하여 사용하는 방법\n",
    "GPU와 같은 하드웨어에서 메모리 사용량을 줄이고 계산 속도를 높이기 위해 사용\n",
    "\"\"\"\n",
    "mixed_precision.set_global_policy('mixed_float16')  # 모델 훈련에 혼합 정밀도(16-bit float)를 사용하도록 설정\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "\"\"\"\n",
    "하이퍼파라미터는 모델 성능과 학습 속도에 큰 영향을 미침\n",
    "\"\"\"\n",
    "batch_size = 128  # 한 번에 학습할 데이터의 개수\n",
    "img_size = (256, 256)  # 입력 이미지 크기\n",
    "latent_dim = 100  # 생성자의 잠재 공간 차원\n",
    "n_critic = 10  # Critic 네트워크를 한 번에 몇 번 업데이트할지 설정\n",
    "lambda_gp = 10.0  # Gradient Penalty의 가중치, Critic을 위한 정규화 항\n",
    "epochs = 50  # 전체 학습을 몇 번 반복할지 설정\n",
    "\n",
    "def make_dataset(original_dir, adjust_dir, batch_size=batch_size):\n",
    "    \"\"\"학습, 검증, 테스트 데이터셋을 생성하는 함수\"\"\"\n",
    "    original_images = sorted(os.listdir(original_dir))\n",
    "    dataset_pairs = []\n",
    "\n",
    "    for original_image in original_images:\n",
    "        base_name = original_image.replace(\"_rgb.png\", \"\")\n",
    "        adjust_image = base_name + \"_rgb_adjusted_0.png\"\n",
    "        original_path = os.path.join(original_dir, original_image)\n",
    "        adjust_path = os.path.join(adjust_dir, adjust_image)\n",
    "        if os.path.exists(original_path) and os.path.exists(adjust_path):\n",
    "            dataset_pairs.append((adjust_path, original_path))\n",
    "        else:\n",
    "            print(f\"Missing file: {original_path} or {adjust_path}\")\n",
    "\n",
    "    train_pairs, val_pairs, test_pairs = split_dataset(dataset_pairs)\n",
    "    \n",
    "    train_dataset, train_samples = make_tf_dataset(train_pairs)\n",
    "    val_dataset, val_samples = make_tf_dataset(val_pairs)\n",
    "    test_dataset, test_samples = make_tf_dataset(test_pairs)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, train_samples, val_samples, test_samples\n",
    "\n",
    "def split_dataset(dataset_pairs):\n",
    "    \"\"\"데이터셋을 학습, 검증, 테스트 세트로 나누는 함수\"\"\"\n",
    "    total_len = len(dataset_pairs)\n",
    "    train_len = int(total_len * 0.7)\n",
    "    val_len = int(total_len * 0.2)\n",
    "    test_len = total_len - train_len - val_len\n",
    "\n",
    "    train_pairs = dataset_pairs[:train_len]\n",
    "    val_pairs = dataset_pairs[train_len:train_len + val_len]\n",
    "    test_pairs = dataset_pairs[train_len + val_len:]\n",
    "\n",
    "    return train_pairs, val_pairs, test_pairs\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"이미지를 불러와 전처리하는 함수\"\"\"\n",
    "    try:\n",
    "        image = load_img(image_path, target_size=img_size)\n",
    "        image = img_to_array(image) / 255.0\n",
    "        if np.isnan(image).any():\n",
    "            raise ValueError(f\"NaN detected in image: {image_path}\")\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def make_tf_dataset(pairs):\n",
    "    \"\"\"TensorFlow 데이터셋을 생성하는 함수\"\"\"\n",
    "    def data_generator():\n",
    "        for original_path, adjust_path in pairs:\n",
    "            original_image = load_and_preprocess_image(original_path)\n",
    "            adjust_image = load_and_preprocess_image(adjust_path)\n",
    "            if original_image is None or adjust_image is None:\n",
    "                continue\n",
    "            yield original_image, adjust_image\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        data_generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(img_size[0], img_size[1], 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(img_size[0], img_size[1], 3), dtype=tf.float32)\n",
    "        )\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE).cache()\n",
    "    return dataset, len(pairs)\n",
    "\n",
    "# 데이터셋 디렉토리 경로\n",
    "original_dir = 'your_path'  # 원본 이미지 디렉토리 경로\n",
    "adjust_dir = 'your_path'  # 조정된 이미지 디렉토리 경로\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset, val_dataset, test_dataset, train_samples, val_samples, test_samples = make_dataset(original_dir, adjust_dir)\n",
    "\n",
    "# Generator 정의\n",
    "def build_generator():\n",
    "    \"\"\"Generator 모델을 구축하는 함수\"\"\"\n",
    "    input_img = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "    ref_img = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "\n",
    "    x = tf.keras.layers.Concatenate()([input_img, ref_img])\n",
    "    x = conv_block(x, 64)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = conv_block(x, 128)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = conv_block(x, 256)\n",
    "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "    x = conv_block(x, 128)\n",
    "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "    x = conv_block(x, 64)\n",
    "    output_img = tf.keras.layers.Conv2D(3, (3, 3), padding='same', activation='sigmoid')(x)\n",
    "\n",
    "    return tf.keras.models.Model([input_img, ref_img], output_img)\n",
    "\n",
    "def conv_block(x, filters):\n",
    "    \"\"\"컨볼루션 블록을 생성하는 함수\"\"\"\n",
    "    x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    return x\n",
    "\n",
    "# Critic 정의\n",
    "def build_critic():\n",
    "    \"\"\"Critic 모델을 구축하는 함수\"\"\"\n",
    "    input_img = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "\n",
    "    x = conv_block(input_img, 64)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = conv_block(x, 128)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = conv_block(x, 256)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
    "    x = conv_block(x, 512)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "    return tf.keras.models.Model(input_img, output)\n",
    "\n",
    "# 손실 함수 및 Gradient Penalty 계산\n",
    "\"\"\"\n",
    "Wasserstein 거리와 Gradient Penalty는 WGAN-GP 모델의 핵심 요소로, 모델 학습의 안정성을 크게 향상시킴\n",
    "\"\"\"\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "def gradient_penalty(critic, real_images, fake_images):\n",
    "    \"\"\"Gradient Penalty를 계산하는 함수\"\"\"\n",
    "    batch_size = tf.shape(real_images)[0]\n",
    "    alpha = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0, dtype=real_images.dtype)\n",
    "    real_images = tf.cast(real_images, tf.float32)\n",
    "    fake_images = tf.cast(fake_images, tf.float32)\n",
    "    interpolated = alpha * real_images + (1 - alpha) * fake_images\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated)\n",
    "        validity_interpolated = critic(interpolated)\n",
    "\n",
    "    gradients = tape.gradient(validity_interpolated, [interpolated])[0]\n",
    "    gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
    "    gradient_penalty = tf.reduce_mean((gradients_norm - 1.0) ** 2)\n",
    "    return gradient_penalty\n",
    "\n",
    "@tf.function\n",
    "def train_step(generator, critic, input_img, ref_img, optimizer_G, optimizer_C):\n",
    "    \"\"\"단일 학습 스텝을 수행하는 함수\"\"\"\n",
    "    batch_size = input_img.shape[0]\n",
    "\n",
    "    # Generator 학습\n",
    "    with tf.GradientTape() as tape:\n",
    "        fake_images = generator([input_img, ref_img])\n",
    "        fake_images = tf.cast(fake_images, tf.float32)\n",
    "        fake_validity = critic(fake_images)\n",
    "        generator_loss = -tf.reduce_mean(tf.cast(fake_validity, tf.float32))\n",
    "\n",
    "    grads = tape.gradient(generator_loss, generator.trainable_variables)\n",
    "    optimizer_G.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "\n",
    "    # Critic 학습\n",
    "    for _ in range(n_critic):\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = generator([input_img, ref_img])\n",
    "            real_validity = critic(ref_img)\n",
    "            fake_validity = critic(fake_images)\n",
    "            gp = gradient_penalty(critic, ref_img, fake_images)\n",
    "            critic_loss = (tf.reduce_mean(tf.cast(fake_validity, tf.float32)) -\n",
    "                           tf.reduce_mean(tf.cast(real_validity, tf.float32)) +\n",
    "                           lambda_gp * tf.cast(gp, tf.float32))\n",
    "\n",
    "        grads = tape.gradient(critic_loss, critic.trainable_variables)\n",
    "        optimizer_C.apply_gradients(zip(grads, critic.trainable_variables))\n",
    "\n",
    "    return generator_loss, critic_loss\n",
    "\n",
    "@tf.function\n",
    "def validation_step(generator, critic, input_img, ref_img):\n",
    "    \"\"\"단일 검증 스텝을 수행하는 함수\"\"\"\n",
    "    fake_images = generator([input_img, ref_img])\n",
    "    fake_images = tf.cast(fake_images, tf.float32)\n",
    "    real_validity = critic(ref_img)\n",
    "    fake_validity = critic(fake_images)\n",
    "    gp = gradient_penalty(critic, ref_img, fake_images)\n",
    "    critic_loss = (tf.reduce_mean(tf.cast(fake_validity, tf.float32)) -\n",
    "                   tf.reduce_mean(tf.cast(real_validity, tf.float32)) +\n",
    "                   lambda_gp * tf.cast(gp, tf.float32))\n",
    "    generator_loss = -tf.reduce_mean(tf.cast(fake_validity, tf.float32))\n",
    "\n",
    "    return generator_loss, critic_loss\n",
    "\n",
    "def train(generator, critic, train_dataset, val_dataset, epochs, batch_size):\n",
    "    \"\"\"모델을 학습하는 함수\"\"\"\n",
    "    optimizer_G = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.5, beta_2=0.9)\n",
    "    optimizer_C = tf.keras.optimizers.Adam(learning_rate=0.00005, beta_1=0.5, beta_2=0.9)\n",
    "\n",
    "    best_val_g_loss = np.inf\n",
    "    best_val_c_loss = np.inf\n",
    "\n",
    "    train_gen_losses, train_critic_losses, val_gen_losses, val_critic_losses = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_gen_loss, epoch_critic_loss = [], []\n",
    "        train_dataset_tqdm = tqdm(train_dataset, desc=f'Epoch {epoch+1}/{epochs}', ncols=100, unit='batch')\n",
    "\n",
    "        for input_img, ref_img in train_dataset_tqdm:\n",
    "            per_replica_g_loss, per_replica_c_loss = strategy.run(\n",
    "                train_step, args=(generator, critic, input_img, ref_img, optimizer_G, optimizer_C))\n",
    "            g_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_g_loss, axis=None)\n",
    "            c_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_c_loss, axis=None)\n",
    "            epoch_gen_loss.append(g_loss.numpy())\n",
    "            epoch_critic_loss.append(c_loss.numpy())\n",
    "            train_dataset_tqdm.set_postfix({'g_loss': np.mean(epoch_gen_loss), 'c_loss': np.mean(epoch_critic_loss)})\n",
    "\n",
    "        train_gen_losses.append(np.mean(epoch_gen_loss))\n",
    "        train_critic_losses.append(np.mean(epoch_critic_loss))\n",
    "\n",
    "        val_gen_loss, val_critic_loss = validate_model(generator, critic, val_dataset)\n",
    "        val_gen_losses.append(val_gen_loss)\n",
    "        val_critic_losses.append(val_critic_loss)\n",
    "\n",
    "        save_model(generator, critic, epoch)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{epochs}, Generator Loss: {np.mean(epoch_gen_loss)}, Critic Loss: {np.mean(epoch_critic_loss)}\")\n",
    "        print(f\"Validation Generator Loss: {val_gen_loss}, Validation Critic Loss: {val_critic_loss}\")\n",
    "\n",
    "    return train_gen_losses, train_critic_losses, val_gen_losses, val_critic_losses\n",
    "\n",
    "def validate_model(generator, critic, val_dataset):\n",
    "    \"\"\"모델을 검증하는 함수\"\"\"\n",
    "    val_epoch_gen_loss, val_epoch_critic_loss = [], []\n",
    "    for input_img, ref_img in val_dataset:\n",
    "        per_replica_val_g_loss, per_replica_val_c_loss = strategy.run(validation_step, args=(generator, critic, input_img, ref_img))\n",
    "        val_g_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_val_g_loss, axis=None)\n",
    "        val_c_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_val_c_loss, axis=None)\n",
    "        val_epoch_gen_loss.append(val_g_loss.numpy())\n",
    "        val_epoch_critic_loss.append(val_c_loss.numpy())\n",
    "\n",
    "    val_gen_loss = np.mean(val_epoch_gen_loss)\n",
    "    val_critic_loss = np.mean(val_epoch_critic_loss)\n",
    "\n",
    "    return val_gen_loss, val_critic_loss\n",
    "\n",
    "def save_model(generator, critic, epoch):\n",
    "    \"\"\"모델을 저장하는 함수\"\"\"\n",
    "    generator.save(f'your_path')\n",
    "    critic.save(f'your_path')\n",
    "\n",
    "# MirroredStrategy 설정\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    generator = build_generator()\n",
    "    critic = build_critic()\n",
    "\n",
    "    generator.summary()\n",
    "    critic.summary()\n",
    "\n",
    "    train_gen_losses, train_critic_losses, val_gen_losses, val_critic_losses = train(\n",
    "        generator, critic, train_dataset, val_dataset, epochs, batch_size)\n",
    "\n",
    "# 학습 과정 시각화\n",
    "def plot_losses(train_gen_losses, val_gen_losses, train_critic_losses, val_critic_losses):\n",
    "    \"\"\"학습 및 검증 손실을 시각화하는 함수\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_gen_losses, label='Train Generator Loss')\n",
    "    plt.plot(val_gen_losses, label='Validation Generator Loss')\n",
    "    plt.plot(train_critic_losses, label='Train Critic Loss')\n",
    "    plt.plot(val_critic_losses, label='Validation Critic Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "plot_losses(train_gen_losses, val_gen_losses, train_critic_losses, val_critic_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
